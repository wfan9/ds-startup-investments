---
title: "Predicting Startup Status"
author: "William Fang"
date: "15/06/2020"
geometry: "left=3cm,right=3cm,top=2cm,bottom=2cm"
bibliography: references-dl.bib
link-citations: true
nocite: '@*'
output:
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE, cache = TRUE, comment = NA)

# Save/load computationally expensive data to/from file to save time during development.
use_cache <- FALSE
```

```{r download-bibliography}
#download.file(
```

# Introduction

@@@@ Rework to focus on this dataset, not representative of startups in general, put that in results
discussion. Also not well defined the time range.

While "Unicorn" startups (companies valued at over \$1 billion) receive the most coverage, the vast majority
of startups fail. Various statistics on the failure rate can be found on the internet, (90% according to
@startup-fail-90), but in general terms the odds of success are small. The aim of this report is to develop a
model to predict the status of a startup based primarily on the funding of the company. The data set used is
"StartUp Investments (Crunchbase)", available from Kaggle. It provides the status of a company (acquired,
operating, or closed), funding and other feature data.

@@@@ Section that describes the dataset and variables, and summarizes the goal of the project and key steps that were performed.

Steps:

    Load and clean the data.

    Split into training and validation sets.

    Explore the data.

    Create and train models, 

    Test against validation set


```{r required-packages, cache = FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
```

```{r data-setup}

dl <- tempfile()
download.file("https://github.com/wfan9/ds-startup-investments/raw/master/data/517018_952128_compressed_investments_VC.csv.zip", dl)
data <- read_csv(unzip(dl))

str(data)

rm(dl)
```
The data set can be downloaded as a zipped CSV file, and has been added to the github repository of this
project. The uncompressed file is approximately 12Mb, and there are `r nrow(data)` rows, and
`r length(names(data))` variables.

## Variables

The variable names are as below:

```{r variables-table, include = TRUE}
names(data)
```

The data set has no meta data explaining the definitions of the features, and instead reasonable
interpretations are assumed.

### Market and Categories

The `market` variable is string representing the main market the startup is targeting.
`category_list` contains one or more categories the startup belongs to. Each category is separated by a |, and
there is no specific ordering to the list.

```{r category_list-sample, include = TRUE}
kable(head(data$category_list), caption = "Sample category_list Values")
```

### Name

Startup name, there may be some sort of predictive power here. For example, a catchy or memorable startup name
might attract more attention and lead to more investment, consumer interest etc.

### Location

There are four variables that describe location.  `country_code` which is a 3 character string, `state_code` a
2 character string for companies within the US, `region` and `city` which are strings.

### Status

The focus of this report is to create a model for predicting status. The variable `status` has the following values:

```{r status-values, include = TRUE}
kable(unique(data$status), caption = "Status Values")
```
There are companies with a missing status value, these will be removed as they can't be used.

### Date

@@@@ Describe

founded_at
founded_month
founded_quarter
founded_year
first_funding_at
last_funding_at

### Funding

@@@@ Describe

funding_total_usd
funding_rounds
seed
venture
equity_crowdfunding
undisclosed
convertible_note
debt_financing
angel
grant
private_equity
post_ipo_equity
post_ipo_debt
secondary_market
product_crowdfunding

round_A
round_B
round_C
round_D             
round_E
round_F
round_G
round_H


### Ignored Variables

The following variables will be ignored, as they are very unlikely to have any predictive power. `permalink`,
which is a hyperlink from the Techcrunch data, and `homepage_url`, which is the company's web page.


# Analysis

## Data Exploration And Analysis

The first step is to examine the data, looking for missing data, bad/invalid values, and possible
transformations that will improve the accuracy of the classification model being developed.

### Missing Values

The following table shows the counts of missing (NA) values in the data set:

```{r missing-values-counts-table, include = TRUE}
missing_values <- data %>%
    gather(key = "variable", value = "val") %>%
    mutate(missing = is.na(val)) %>%
    group_by(variable, missing) %>%
    summarise(count = n()) %>%
    filter(missing==TRUE) %>%
    select(-missing) %>%
    arrange(desc(count)) 

kable(missing_values, caption = "Variables With Missing Values Counts")
rm(missing_values)
```
    
There are a few variables where there is only 1 NA value, and it turns out they all belong to one entry which
can be removed.

```{r remove-bad-row}
data <- data %>% filter(!is.na(angel))
```

The following plot shows the percentage of a variable that has NA values (code adapted from @vis-miss-value):

```{r missing-values-plot, include = TRUE}
# Count how many NAs per variable type, then work out percentage.
missing_values <- data %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num_isna = n()) %>%
  mutate(pct = num_isna / total * 100)

# Order so that least missing are first, this will be used as scale labels.
levels <- (missing_values %>% filter(isna == TRUE) %>% arrange(desc(pct)))$key

percentage_plot <- missing_values %>%
  ggplot() +
  geom_bar(aes(x = reorder(key, desc(pct)), y = pct, fill=isna),  stat = 'identity', alpha=0.8) +
  scale_x_discrete(limits = levels) +
  scale_fill_manual(name = "", values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
  coord_flip() +
  labs(title = "Percentage of missing values", x = 'Variable', y = "% of missing values")

percentage_plot
#rm(missing_values, levels, percentage_plot)
```

Handling of NA values for the rest of the variables will be discussed in the following sections.

### Status

Since the aim is to predict the status of a company, the rows that don't have a valid status can't be used and
are simply removed. The data type is changed from character to factor. Then the counts of the 3 statuses can
be seen:

```{r clean-transform-status}
data <- data %>% filter(!is.na(status)) %>% mutate(status = factor(status))
```
```{r status-hist-plot}
ggplot(aes(data$status)) + geom_hist()
```


@@@@ Turn status, country, state etc into factors. Dates from strings to datetime.

@@@@ What to use for measuring accuracy/loss function?

## Models

@@@@ section that explains the process and techniques used, including data cleaning, data exploration and visualization, any insights gained, and your modeling approach. At least two different models or algorithms must be used, with at least one being more advanced than simple linear regression for prediction problems.

# Results 

@@@@ A results section that presents the modeling results and discusses the model performance.

# Conclusion

@@@@ A conclusion section that gives a brief summary of the report, its potential impact, its limitations, and future work.


# Bibliography

